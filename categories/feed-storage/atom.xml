<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: feed storage | Blog | OpenEnergyMonitor]]></title>
  <link href="https://blog.openenergymonitor.org/categories/feed-storage/atom.xml" rel="self"/>
  <link href="https://blog.openenergymonitor.org/"/>
  <updated>2019-06-11T13:21:46+00:00</updated>
  <id>https://blog.openenergymonitor.org/</id>
  <author>
    <name><![CDATA[Glyn Hudson]]></name>
    <email><![CDATA[support@openenergymonitor.zendesk.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[More direct file storage research]]></title>
    <link href="https://blog.openenergymonitor.org/2013/07/more-direct-file-storage-research/"/>
    <updated>2013-07-04T12:04:00+00:00</updated>
    <id>https://blog.openenergymonitor.org/2013/07/more-direct-file-storage-research</id>
    <content type="html"><![CDATA[<p>I was surprised to find how easy it was to use flat file storage for feed data using PHP file access commands and how fast this approach could be.<br /><br />While reading up on indexes I realised that the timestamp column in a feed data table is its own index as it is naturally sorted in ascending order and each row (datapoint) should be unique. A data-point can then be searched for efficiently using binary search which I remember covering in A-level computing. The feed data in mysql had a binary tree index which If I understand correctly is similar but it is implemented using a separate index layer which uses quite a bit of extra disk space. <br /><br />I had a go at implementing the get_feed_data function used in emoncms to select a given number of datapoint’s over a timewindow used for drawing graphs. An example of the standalone function can be found here: <br /><br /><a href="https://github.com/emoncms/experimental/blob/master/storage/directfiles/get_feed_data.php">https://github.com/emoncms/experimental/blob/master/storage/directfiles/get_feed_data.php</a> <br /><br />A development branch of emoncms that uses this flat file approach and includes this function can be found here (inserting data, input processing such as power to kwhd and visualisation all work, but its still quite conceptual) <br /><br /><a href="https://github.com/emoncms/emoncms/tree/flatfilestore">https://github.com/emoncms/emoncms/tree/flatfilestore</a> <br /><br />The get_feed_data function as implemented above takes roughly 120-230ms on a RaspberryPI to select 1000 datapoints over 1 to 300 days with a feed table with over 9 million rows. <br /><br />Thats much better than the 900-2700ms achieved at similar ranges with the <a href="http://openenergymonitor.blogspot.co.uk/2013/06/rethinking-data-input-and-storage-core.html">current mysql implementation</a>. <br /><br />The feed table in mysql used 178Mb of disk space. The same feed with no loss of data stored without an index and accessed as above takes up 67Mb so that’s a considerable saving. Interestingly a 67Mb feed can be compressed to 18.5Mb with tar.gz compression. <br /><br />One of the issues with the above get_feed_data query is that it needs to know the data interval to do the get a datapoint every x number of datapoints approach. We could use binary search to find every datapoint but this would be slower although maybe worth trying to get a benchmark so that it can be compared. <br /><br />The other issue is that the datapoints selected may not be representative of the window they represent as they are just one random datapoint at a particular point in time. Which is the problem that the averaging approach used by <a href="http://mikestirling.co.uk/redmine/projects/timestore">Mike Stirling in Timestore </a>and by <a href="https://github.com/dovadi/emonWeb">Frank Oakner in EmonWeb</a> solves. <br /><br />Timestore is also a fair bit faster than the above get_feed_data function returning 1000 datapoints in 45ms. <br /><br />The advantage of the above approach is that it can fit into emoncms without having to change the current implementation too much, the feed data retains its timestamps, input processing is used in the same way. <br /><br />Not storing timestamps as timestore does could also be an advantage as it helps keep data quality high: fixed interval datapoints should be easier to use for comparison’s, mathematical operations between feeds, it gives you higher certainty when querying the data, fetching data is faster and disk use is potentially half the size of the above approach if the values are stored as <a href="http://openenergymonitor.blogspot.com/2013/06/timestore-timeseries-database.html">4 byte floats as above rather than the default 8 byte double</a>. This coupled with averaged layers provides data that is representative at all time scales and datapoint number requests. <br /><br />My next step will therefore be to explore timestore further, first creating a script to export data from emoncms into timestore. The script needs to analyse the emoncms feed to work out the most common data interval. It needs to check for missing data, If a monitor went offline for an extended length of time it needs to give you the option to take this into account. It then needs to export and import into timestore as efficiently as possible.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[In memory storage: PHP shared memory vs Redis vs MYSQL]]></title>
    <link href="https://blog.openenergymonitor.org/2013/07/in-memory-storage-php-shared-memory-vs/"/>
    <updated>2013-07-04T09:25:00+00:00</updated>
    <id>https://blog.openenergymonitor.org/2013/07/in-memory-storage-php-shared-memory-vs</id>
    <content type="html"><![CDATA[<p>Continuing on the theme of rethinking the data core of emoncms, as <a href="http://openenergymonitor.blogspot.co.uk/2013/06/rethinking-data-input-and-storage-core.html">previously mentioned</a> for short term storage, storage to disk may not be necessary, instead we can store data in memory using an in-memory database. Here are some tests and benchmarks for in memory storage:<br />&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;To start with I created baseline test using MYSQL updating a feed’s last time and value in the feeds table row for that feed. This took around: 4800 – 5100 ms to update a row 10000 times.&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<a href="https://github.com/emoncms/experimental/blob/master/storage/inmemory/baselinemysql.php">https://github.com/emoncms/experimental/blob/master/storage/inmemory/baselinemysql.php</a>&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;We would imagine Redis doing a lot better as its in-memory, it isn’t writing to disk each time which is much slower than memory access. Redis did indeed perform faster completing the same number of updates to a key-value pair in 1900 – 2350ms. I’m a little surprised thought that it was only 2.3x as fast and not much faster, but then there is a lot going on Redis has its own server which needs to be accessed from the PHP client this is going to slow things down a bit, I tested both the phpredis client and Predis. Phpredis was between 500-1000 ms faster than the Predis client and is written in c.&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<a href="https://github.com/emoncms/experimental/blob/master/storage/inmemory/redis.php">https://github.com/emoncms/experimental/blob/master/storage/inmemory/redis.php</a>&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;How fast can in-memory storage be? A general program variable is also a form of in-memory storage, a quick test suggests that it takes 21ms to write to a program variable 10000 times, much better than 2.3x faster that’s 230x faster! The problem with in program variables is that if they are written to in one script say an instance of input/post they cannot be accessed by another instance serving feed/list, we need some form of storage that can be accessed across different instances of scripts.&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<a href="https://github.com/emoncms/experimental/blob/master/storage/inmemory/programvariable.php">https://github.com/emoncms/experimental/blob/master/storage/inmemory/programvariable.php</a>&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;The difference between 21ms and 1900-2350ms for redis is intriguingly large and so I thought I would search for other ways of storing data in-memory that would allow access between different application scripts and instances.&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;I came across the PHP shared memory functions which are similar to the flat file access but for memory, the results of a simple test are encouraging showing a write time of 48ms for 10000 updates. So from a performance perspective using php shared memory looks like a better way of doing things.  &lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<a href="https://github.com/emoncms/experimental/blob/master/storage/inmemory/sharedmemory.php">https://github.com/emoncms/experimental/blob/master/storage/inmemory/sharedmemory.php</a>&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;The issue though is implementation, mysql made it really easy to search for the feed rows that you wanted (either by selecting by feed id or by feeds that belong to a user or feeds that are public), I’m a little unsure about how best to implement the similar functionality in redis but it looks like it may be possible by just storing each feed meta data roughly like this: feed_1: {“time”:1300,”value”:20}.  &lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;<br />&lt;/div&gt;&lt;div style="margin-bottom: 0cm;"&gt;Shared memory though looks like it could be quite a bit more complicated to implement, but then it does appear to be much faster. Maybe the 2.3x speed improvement over mysql offered by redis is fast enough? and its probably much faster in high-concurrency situations. I think more testing and attempts at writing full implementations using each approach is needed before a definitive answer can be reached.&lt;/div&gt;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Load stat's for MYISAM vs INNODB for feed storage on the RaspberryPI]]></title>
    <link href="https://blog.openenergymonitor.org/2013/06/load-stats-for-myisam-vs-innodb-for/"/>
    <updated>2013-06-28T08:26:00+00:00</updated>
    <id>https://blog.openenergymonitor.org/2013/06/load-stats-for-myisam-vs-innodb-for</id>
    <content type="html"><![CDATA[<p>Here are some historic load stats for a raspberrypi running here, with 36 feeds being written to.<br />&lt;div&gt;<br />&lt;/div&gt;&lt;div&gt;First using the INNODB storage engine:<br />&lt;div class="separator" style="clear: both; text-align: center;"&gt;<span style="text-align: left;"><br /></span>&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;<a href="http://3.bp.blogspot.com/-TDFZZ7cyfbE/Uc1E7dSLCeI/AAAAAAAACtI/vbG7etiFS2g/s925/innodb_raspi_load.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="280" src="http://3.bp.blogspot.com/-TDFZZ7cyfbE/Uc1E7dSLCeI/AAAAAAAACtI/vbG7etiFS2g/s640/innodb_raspi_load.png" width="640" /></a>&lt;/div&gt;A load of 3.5 causes an issue where the time that is recorded for data packets coming in gets messed up creating bunched up datapoints:<br />&lt;div class="separator" style="clear: both; text-align: center;"&gt;<a href="http://4.bp.blogspot.com/-Jhg1mpnwIMQ/Uc1HL91zhjI/AAAAAAAACtg/h-vzID3xHro/s948/timingissue.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="270" src="http://4.bp.blogspot.com/-Jhg1mpnwIMQ/Uc1HL91zhjI/AAAAAAAACtg/h-vzID3xHro/s640/timingissue.png" width="640" /></a>&lt;/div&gt;<br />Switching the storage engine over the MYISAM, reduced the load to around 0.2 and the timing issue is no longer present:<br /><br />&lt;div class="separator" style="clear: both; text-align: center;"&gt;<a href="http://4.bp.blogspot.com/-vPe12-x2Gtc/Uc1FAYirGeI/AAAAAAAACtQ/Q5bp_VsvwmQ/s944/piloadmyisam.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="274" src="http://4.bp.blogspot.com/-vPe12-x2Gtc/Uc1FAYirGeI/AAAAAAAACtQ/Q5bp_VsvwmQ/s640/piloadmyisam.png" width="640" /></a>&lt;/div&gt;<br />To convert your raspberry pi emoncms Innodb tables to MYISAM you can run the following script on your raspberrypi which will go through each table converting them in turn:<br /><br /><br /><br />  $mysqli = new mysqli(“localhost”,”root”,”raspberry”,”emoncms”);<br /><br />  $result = $mysqli-&gt;query(“SHOW tables”);<br />  while ($row = $result-&gt;fetch_array())<br />  {<br />    echo “ALTER TABLE <code class="highlighter-rouge">".$row[0]."</code> ENGINE=MYISAM\n”;<br />    $mysqli-&gt;query(“ALTER TABLE <code class="highlighter-rouge">".$row[0]."</code> ENGINE=MYISAM”);<br />  }<br /><br />&lt;/div&gt;</p>
]]></content>
  </entry>
  
</feed>
